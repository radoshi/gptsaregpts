{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import baserun\n",
    "import csv\n",
    "import openai\n",
    "import os\n",
    "import tiktoken\n",
    "import json\n",
    "from pydantic import BaseModel\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import Tuple\n",
    "from tenacity import retry, wait_random_exponential\n",
    "\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set API keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rushabh/Library/Caches/pypoetry/virtualenvs/gptsaregpts-bRn197-3-py3.11/lib/python3.11/site-packages/baserun/baserun.py:44: UserWarning: Baserun has already been initialized. Additional calls to init will be ignored.\n",
      "  warnings.warn(\"Baserun has already been initialized. Additional calls to init will be ignored.\")\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "baserun.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "\n",
    "def connect(name: str) -> Tuple[sqlite3.Connection, sqlite3.Cursor]:\n",
    "    conn = sqlite3.connect(name)\n",
    "    c = conn.cursor()\n",
    "    return conn, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn, c = connect(\"../db.sqlite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the tokens for the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"45\": 100, \"15\": 100, \"16\": 100, \"17\": 100, \"18\": 100}\n"
     ]
    }
   ],
   "source": [
    "def get_tokens() -> dict:\n",
    "    encoding = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "    tokens = [encoding.encode(label) for label in [\"0\", \"1\", \"2\", \"3\", \"N\"]]\n",
    "\n",
    "    # Flatten the list of lists and convert to a set.\n",
    "    token_set = set([item for sublist in tokens for item in sublist])\n",
    "\n",
    "    # Create a dictionary with the tokens and a default value of 100.\n",
    "    token_dict = {str(token): 100 for token in token_set}\n",
    "\n",
    "    return token_dict\n",
    "\n",
    "\n",
    "logit_bias = get_tokens()\n",
    "print(json.dumps(logit_bias))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~Create the classification table if it doesn't exist already.~~\n",
    "\n",
    "We don't need a classification table anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classification_table(c: sqlite3.Cursor, conn: sqlite3.Connection) -> None:\n",
    "    dwa_classification_sql = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS dwa_classification (\n",
    "        onetsoc_code CHARACTER(10) NOT NULL,\n",
    "        task_id DECIMAL(8,0) NOT NULL,    \n",
    "        dwa_id CHARACTER VARYING(20) NOT NULL,\n",
    "        classification CHARACTER(2) NOT NULL,\n",
    "        FOREIGN KEY (onetsoc_code) REFERENCES occupation_data(onetsoc_code),\n",
    "        FOREIGN KEY (task_id) REFERENCES task_statements(task_id),\n",
    "        FOREIGN KEY (dwa_id) REFERENCES dwa_reference(dwa_id),\n",
    "        PRIMARY KEY (onetsoc_code, task_id, dwa_id)\n",
    "    );\n",
    "    \"\"\"\n",
    "\n",
    "    c.execute(dwa_classification_sql)\n",
    "    conn.commit()\n",
    "\n",
    "\n",
    "# create_classification_table(c, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "user_template = Path(Path.cwd().parent / \"prompts\" / \"user.txt\").read_text()\n",
    "system_template = Path(Path.cwd().parent / \"prompts\" / \"system.txt\").read_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch all the rows from the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DWAReference(BaseModel):\n",
    "    dwa_id: str\n",
    "    dwa_title: str\n",
    "    classification: str | None = None\n",
    "\n",
    "    @classmethod\n",
    "    def from_tuple(cls, tup: tuple):\n",
    "        return cls(\n",
    "            dwa_id=tup[0],\n",
    "            dwa_title=tup[1],\n",
    "        )\n",
    "    \n",
    "    @retry(wait=wait_random_exponential(multiplier=1, max=60))\n",
    "    async def classify(self) -> str:\n",
    "        user_message = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_template.format(\n",
    "                task=self.dwa_title,\n",
    "            ),\n",
    "        }\n",
    "        system_message = {\"role\": \"system\", \"content\": system_template}\n",
    "\n",
    "        response = await openai.ChatCompletion.acreate(\n",
    "            messages=[system_message, user_message],\n",
    "            logit_bias=logit_bias,\n",
    "            max_tokens=1,\n",
    "            temperature=0,\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "        )\n",
    "        self.classification = response.choices[0][\"message\"][\"content\"]\n",
    "        return self.classification\n",
    "\n",
    "    def save(self, c: sqlite3.Cursor) -> None:\n",
    "        insert_sql = \"UPDATE dwa_reference SET classification = ? WHERE dwa_id = ?\"\n",
    "        c.execute(insert_sql, (self.classification, self.dwa_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_rows(c: sqlite3.Cursor, num: int = -1) -> list:\n",
    "    select_query = \"\"\"\n",
    "select    \n",
    "  t.dwa_id,\n",
    "  t.dwa_title\n",
    "from\n",
    "  dwa_reference as t\n",
    "where\n",
    "  t.classification is null\n",
    "order by\n",
    "  t.dwa_id\n",
    "  \"\"\"\n",
    "    c.execute(select_query)\n",
    "    if num == -1:\n",
    "        return [DWAReference.from_tuple(r) for r in c.fetchall()]\n",
    "    else:\n",
    "        return [DWAReference.from_tuple(r) for r in c.fetchmany(num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def classify_all(rows: list[DWAReference]) -> None:\n",
    "    for row in tqdm(rows, desc=\"Classifying\"):\n",
    "        await row.classify()\n",
    "        print(f\"[{row.dwa_id}]: {row.dwa_title}: {row.classification}\")\n",
    "        row.save(c)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c7d32eaf0c4424582352583e435d7f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifying: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "occupation_codes = fetch_rows(c, 1000)\n",
    "await classify_all(occupation_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_task_scores():\n",
    "    calculation_sql = \"\"\"\n",
    "    UPDATE task_statements\n",
    "    SET \n",
    "        alpha = (\n",
    "            SELECT \n",
    "                1.0 * SUM(CASE WHEN classification = 1 THEN 1 ELSE 0 END) / COUNT(*)\n",
    "            FROM \n",
    "                tasks_to_dwas\n",
    "            JOIN \n",
    "                dwa_reference ON tasks_to_dwas.dwa_id = dwa_reference.dwa_id\n",
    "            WHERE\n",
    "                tasks_to_dwas.task_id = task_statements.task_id\n",
    "        ),\n",
    "        beta = (\n",
    "            SELECT \n",
    "                1.0 * (SUM(CASE WHEN classification = 1 THEN 1 ELSE 0 END) + 0.5 * SUM(CASE WHEN classification = 2 THEN 1 ELSE 0 END)) / COUNT(*)\n",
    "            FROM \n",
    "                tasks_to_dwas\n",
    "            JOIN \n",
    "                dwa_reference ON tasks_to_dwas.dwa_id = dwa_reference.dwa_id\n",
    "            WHERE\n",
    "                tasks_to_dwas.task_id = task_statements.task_id\n",
    "        ),\n",
    "        zeta = (\n",
    "            SELECT \n",
    "                1.0 * (SUM(CASE WHEN classification = 1 THEN 1 ELSE 0 END) + SUM(CASE WHEN classification = 2 THEN 1 ELSE 0 END) + SUM(CASE WHEN classification = 3 THEN 1 ELSE 0 END)) / COUNT(*)\n",
    "            FROM \n",
    "                tasks_to_dwas\n",
    "            JOIN \n",
    "                dwa_reference ON tasks_to_dwas.dwa_id = dwa_reference.dwa_id\n",
    "            WHERE\n",
    "                tasks_to_dwas.task_id = task_statements.task_id\n",
    "        )\n",
    "    WHERE task_id IN (SELECT task_id FROM tasks_to_dwas);\n",
    "    \"\"\"\n",
    "    c.execute(calculation_sql);\n",
    "    conn.commit();\n",
    "\n",
    "# calculate_task_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_occupation_scores():\n",
    "    occupation_data_sql = \"\"\"\n",
    "        UPDATE occupation_data\n",
    "        SET\n",
    "            alpha = (\n",
    "                SELECT AVG(t.alpha)\n",
    "                FROM task_statements as t\n",
    "                WHERE t.onetsoc_code = occupation_data.onetsoc_code\n",
    "            ),\n",
    "            beta = (\n",
    "                SELECT AVG(t.beta)\n",
    "                FROM task_statements as t\n",
    "                WHERE t.onetsoc_code = occupation_data.onetsoc_code\n",
    "            ),\n",
    "            zeta = (\n",
    "                SELECT AVG(t.zeta)\n",
    "                FROM task_statements as t\n",
    "                WHERE t.onetsoc_code = occupation_data.onetsoc_code\n",
    "            )\n",
    "        ;\n",
    "    \"\"\"\n",
    "    c.execute(occupation_data_sql);\n",
    "    conn.commit();\n",
    "\n",
    "# calculate_occupation_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "Industry and employment numbers from BLS\n",
    "https://www.bls.gov/emp/data/industry-out-and-emp.htm\n",
    "\n",
    "CPS ONET crosswalks\n",
    "https://www.bls.gov/emp/documentation/crosswalks.htm\n",
    "\n",
    "We have to somehow map the major industry group by alpha, beta, and zeta. Steps:\n",
    "1. Major industry group NAICS code -> List of NEM codes.\n",
    "2. ✅ NEM codes -> ONET codes.\n",
    "3. Calculate scores per major industry group.\n",
    "\n",
    "Breakthrough!\n",
    "- EP data tables: https://www.bls.gov/emp/tables.htm\n",
    "- [industry-occupation-matrix by industry](https://www.bls.gov/emp/tables/industry-occupation-matrix-industry.htm)\n",
    "- [industry-occupation-matrix by occupation](https://www.bls.gov/emp/tables/industry-occupation-matrix-occupation.htm)\n",
    "\n",
    "There is some annoyance in having to download the individual CSV files, but we can get over that. This should help us do weighted exposure per industry. \n",
    "Then we can back into major industries by output and by employment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_onet_to_nem_mapping(csv_filepath: Path):\n",
    "    # Open and read the CSV file\n",
    "    with open(csv_filepath, 'r') as f:\n",
    "        csv_reader = csv.DictReader(f)\n",
    "        \n",
    "        # Loop through each row in the CSV file\n",
    "        for row in csv_reader:\n",
    "            onetsoc_code = row['O*NET-SOC Code']\n",
    "            nem_code = row['NEM Code']\n",
    "            nem_title = row['National Employment Matrix Occupational Title']\n",
    "            ooh_profile_code = row['OOH Profile Code']\n",
    "            ooh_profile_title = row['OOH Profile Title']\n",
    "            ooh_occupation_group = row['OOH Occupation Group']\n",
    "            ooh_profile_website = row['OOH Profile Website']\n",
    "\n",
    "            # Insert data into the SQLite table\n",
    "            c.execute(\"\"\"\n",
    "                INSERT INTO bls_onet\n",
    "                (onetsoc_code, nem_code, nem_title, ooh_profile_code, ooh_profile_title, ooh_occupation_group, ooh_profile_website)\n",
    "                VALUES (?, ?, ?, ?, ?, ?, ?)\n",
    "            \"\"\", (onetsoc_code, nem_code, nem_title, ooh_profile_code, ooh_profile_title, ooh_occupation_group, ooh_profile_website))\n",
    "    \n",
    "    # Commit changes and close the connection\n",
    "    conn.commit()\n",
    "    print(\"Added rows to bls_onet table.\")\n",
    "\n",
    "# Usage\n",
    "# populate_onet_to_nem_mapping(Path.cwd().parent / \"data\" / \"bls\" / \"onet_soc_crosswalk.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bls_matrix_csv_to_db(csv_file_path: Path):\n",
    "    with open(csv_file_path, newline='') as csvfile:\n",
    "        csvreader = csv.reader(csvfile)\n",
    "        next(csvreader)  # Skip header row\n",
    "\n",
    "        for row in tqdm(csvreader):\n",
    "            occupation_type = row[0]\n",
    "            industry_type = row[1]\n",
    "            occupation_code = row[2]\n",
    "            occupation_title = row[3]\n",
    "            industry_code = row[4]\n",
    "            industry_title = row[5]\n",
    "            employment_2022 = float(row[6])\n",
    "            percent_industry_2022 = float(row[7])\n",
    "            percent_occupation_2022 = float(row[8])\n",
    "\n",
    "            c.execute(\"\"\"\n",
    "                INSERT INTO bls_matrix (\n",
    "                    occupation_type,\n",
    "                    industry_type,\n",
    "                    occupation_code,\n",
    "                    occupation_title,\n",
    "                    industry_code,\n",
    "                    industry_title,\n",
    "                    employment_2022,\n",
    "                    percent_industry_2022,\n",
    "                    percent_occupation_2022\n",
    "                )\n",
    "                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "            \"\"\", (occupation_type, industry_type, occupation_code, occupation_title, industry_code, industry_title, employment_2022, percent_industry_2022, percent_occupation_2022))\n",
    "\n",
    "    conn.commit()\n",
    "\n",
    "# Use the function\n",
    "# load_bls_matrix_csv_to_db(Path.cwd().parent / \"data\" / \"bls\" / \"matrix.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ddbe493fd834aa986954cd46815d4f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6441 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def calculate_bls_occupation_scores():\n",
    "    # Fetch all rows where the occupation type is \"Line item\" and the industry type is \"Line item\"\n",
    "    fetch_rows_sql = \"\"\"\n",
    "SELECT\n",
    "    bm.id,\n",
    "    bm.alpha,\n",
    "    bm.beta,\n",
    "    bm.zeta,\n",
    "    od.alpha,\n",
    "    od.beta,\n",
    "    od.zeta\n",
    "FROM\n",
    "    occupation_data AS od\n",
    "JOIN\n",
    "    bls_onet AS bo ON od.onetsoc_code = bo.onetsoc_code\n",
    "JOIN\n",
    "    bls_matrix as bm ON bm.occupation_code = bo.nem_code\n",
    "WHERE\n",
    "    bm.occupation_type = 'Line item' AND\n",
    "    bm.industry_type = 'Line item' AND\n",
    "    bm.alpha IS NULL AND\n",
    "    od.alpha IS NOT NULL\n",
    "\"\"\"\n",
    "    for rows in tqdm(c.execute(fetch_rows_sql).fetchall()):\n",
    "        id, alpha, beta, zeta, od_alpha, od_beta, od_zeta = rows\n",
    "        update_row_sql = \"\"\"\n",
    "UPDATE bls_matrix\n",
    "SET\n",
    "    alpha = ?,\n",
    "    beta = ?,\n",
    "    zeta = ?\n",
    "WHERE\n",
    "    id = ?\n",
    "\"\"\"\n",
    "        c.execute(update_row_sql, (od_alpha, od_beta, od_zeta, id))\n",
    "\n",
    "    conn.commit();\n",
    "\n",
    "calculate_bls_occupation_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def update_single_row(id: str, alpha: float, beta: float, zeta: float):\n",
    "    update_summary_sql = \"\"\"\n",
    "UPDATE bls_matrix\n",
    "SET\n",
    "    alpha = :alpha,\n",
    "    beta = :beta,\n",
    "    zeta = :zeta\n",
    "WHERE\n",
    "    id = :id\n",
    "\"\"\"\n",
    "    # update the row with the weighted average\n",
    "    c.execute(update_summary_sql, {\"alpha\": alpha, \"beta\": beta, \"zeta\": zeta, \"id\": id})    \n",
    "\n",
    "def sumprod(line_items: list):\n",
    "    # stuff the rows into a pandas dataframe\n",
    "    df = pd.DataFrame(line_items, columns=[\"id\", \"employment_2022\", \"alpha\", \"beta\", \"zeta\"])\n",
    "\n",
    "    # calculate the weighted average of the scores\n",
    "    weighted_alpha = (df[\"employment_2022\"] * df[\"alpha\"]).sum() / df[\"employment_2022\"].sum()\n",
    "    weighted_beta = (df[\"employment_2022\"] * df[\"beta\"]).sum() / df[\"employment_2022\"].sum()\n",
    "    weighted_zeta = (df[\"employment_2022\"] * df[\"zeta\"]).sum() / df[\"employment_2022\"].sum()\n",
    "\n",
    "    return weighted_alpha, weighted_beta, weighted_zeta\n",
    "\n",
    "\n",
    "def calculate_summary_scores_by_industry(industry_code: str):\n",
    "    # Fetch the occupation codes to summarize.\n",
    "    occupation_codes = \"\"\"\n",
    "SELECT\n",
    "    id,\n",
    "    occupation_code\n",
    "FROM\n",
    "    bls_matrix\n",
    "WHERE\n",
    "    industry_code = :industry_code AND\n",
    "    occupation_type = 'Summary' AND\n",
    "    occupation_code != '00-0000'\n",
    "\"\"\"\n",
    "    occupation_codes = c.execute(occupation_codes, {\"industry_code\": industry_code}).fetchall()\n",
    "\n",
    "    # For each row, summarize the Line items.\n",
    "    for row in occupation_codes:\n",
    "        id, occupation_code = row\n",
    "\n",
    "        regexp = occupation_code.rstrip(\"0\").ljust(7, \"_\")\n",
    "\n",
    "        # Fetch the set of rows to summarize by looking at codes that start with the industry code\n",
    "        query_sql = \"\"\"\n",
    "SELECT\n",
    "    id,\n",
    "    employment_2022,\n",
    "    alpha,\n",
    "    beta,\n",
    "    zeta\n",
    "FROM\n",
    "    bls_matrix\n",
    "WHERE\n",
    "    industry_code = :industry_code AND\n",
    "    occupation_code LIKE :regexp    \n",
    "\"\"\"\n",
    "        line_items = c.execute(query_sql, {\"industry_code\": industry_code, \"regexp\": regexp}).fetchall()\n",
    "        if len(line_items) == 0:\n",
    "            print(f\"No line items found.\")\n",
    "            continue\n",
    "\n",
    "        weighted_alpha, weighted_beta, weighted_zeta = sumprod(line_items)\n",
    "\n",
    "        # update the row with the weighted average\n",
    "        update_single_row(id, weighted_alpha, weighted_beta, weighted_zeta)\n",
    "\n",
    "    conn.commit()\n",
    "\n",
    "# Summarize over all industries\n",
    "def calculate_summary_scores():\n",
    "    industry_codes_sql = \"\"\"\n",
    "SELECT\n",
    "  DISTINCT industry_code\n",
    "FROM\n",
    "  bls_matrix\n",
    "\"\"\"\n",
    "    industry_codes = c.execute(industry_codes_sql).fetchall()\n",
    "    for row in tqdm(industry_codes):\n",
    "        industry_code = row[0]\n",
    "        calculate_summary_scores_by_industry(industry_code)\n",
    "        print(f\"Finished {industry_code}\")\n",
    "\n",
    "# calculate_summary_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f762e0b1addc4e238909c65f2c36b586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/426 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished TE1000\n",
      "Finished TE1100\n",
      "Finished TE1200\n",
      "Finished 110000\n",
      "Finished 111000\n",
      "Finished 112000\n",
      "Finished 113000\n",
      "Finished 1131-2\n",
      "Finished 113300\n",
      "Finished 114000\n",
      "Finished 115000\n",
      "Finished 210000\n",
      "Finished 211000\n",
      "Finished 212100\n",
      "Finished 212200\n",
      "Finished 212300\n",
      "Finished 213000\n",
      "Finished 220000\n",
      "Finished 221000\n",
      "Finished 221100\n",
      "Finished 221110\n",
      "Finished 221111\n",
      "Finished 221112\n",
      "Finished 221113\n",
      "Finished 221114\n",
      "Finished 221115\n",
      "Finished 221116\n",
      "Finished 221117\n",
      "Finished 221118\n",
      "Finished 221200\n",
      "Finished 221300\n",
      "Finished 230000\n",
      "Finished 236000\n",
      "Finished 236100\n",
      "Finished 236200\n",
      "Finished 237000\n",
      "Finished 237100\n",
      "Finished 237130\n",
      "Finished 237200\n",
      "Finished 237300\n",
      "Finished 237900\n",
      "Finished 238000\n",
      "Finished 238100\n",
      "Finished 238110\n",
      "Finished 238140\n",
      "Finished 238160\n",
      "Finished 238200\n",
      "Finished 238210\n",
      "Finished 238220\n",
      "Finished 238290\n",
      "Finished 238300\n",
      "Finished 238310\n",
      "Finished 238320\n",
      "Finished 238900\n",
      "Finished 31-330\n",
      "Finished 311000\n",
      "Finished 311100\n",
      "Finished 311200\n",
      "Finished 311300\n",
      "Finished 311400\n",
      "Finished 311500\n",
      "Finished 311600\n",
      "Finished 311700\n",
      "Finished 311800\n",
      "Finished 311900\n",
      "Finished 312000\n",
      "Finished 312100\n",
      "Finished 312200\n",
      "Finished 313-40\n",
      "Finished 313000\n",
      "Finished 314000\n",
      "Finished 315-60\n",
      "Finished 315000\n",
      "Finished 316000\n",
      "Finished 321000\n",
      "Finished 321100\n",
      "Finished 321200\n",
      "Finished 321900\n",
      "Finished 322000\n",
      "Finished 322100\n",
      "Finished 322200\n",
      "Finished 323000\n",
      "Finished 324000\n",
      "Finished 325000\n",
      "Finished 325400\n",
      "Finished 3250A2\n",
      "Finished 3250A1\n",
      "Finished 326000\n",
      "Finished 326100\n",
      "Finished 326200\n",
      "Finished 327000\n",
      "Finished 331000\n",
      "Finished 331100\n",
      "Finished 331200\n",
      "Finished 331300\n",
      "Finished 331400\n",
      "Finished 331500\n",
      "Finished 332000\n",
      "Finished 3320A2\n",
      "Finished 332700\n",
      "Finished 332710\n",
      "Finished 332720\n",
      "Finished 332800\n",
      "Finished 3320A1\n",
      "Finished 333000\n",
      "Finished 333300\n",
      "Finished 333500\n",
      "Finished 333600\n",
      "Finished 3330A1\n",
      "Finished 334000\n",
      "Finished 334100\n",
      "Finished 334200\n",
      "Finished 334300\n",
      "Finished 334400\n",
      "Finished 334500\n",
      "Finished 334600\n",
      "Finished 335000\n",
      "Finished 335100\n",
      "Finished 335200\n",
      "Finished 335300\n",
      "Finished 335900\n",
      "Finished 336000\n",
      "Finished 336100\n",
      "Finished 336200\n",
      "Finished 336300\n",
      "Finished 336400\n",
      "Finished 336500\n",
      "Finished 336600\n",
      "Finished 336900\n",
      "Finished 337000\n",
      "Finished 3370A1\n",
      "Finished 337900\n",
      "Finished 339000\n",
      "Finished 339100\n",
      "Finished 339900\n",
      "Finished 339910\n",
      "Finished 420000\n",
      "Finished 423000\n",
      "Finished 423100\n",
      "Finished 423400\n",
      "Finished 423800\n",
      "Finished 423820\n",
      "Finished 4230A1\n",
      "Finished 424000\n",
      "Finished 424300\n",
      "Finished 424500\n",
      "Finished 4240A2\n",
      "Finished 4240A1\n",
      "Finished 4240A3\n",
      "Finished 425000\n",
      "Finished 44-450\n",
      "Finished 441000\n",
      "Finished 441100\n",
      "Finished 441200\n",
      "Finished 441300\n",
      "Finished 445000\n",
      "Finished 4450A1\n",
      "Finished 445300\n",
      "Finished 455000\n",
      "Finished 4445R0\n",
      "Finished 444000\n",
      "Finished 444100\n",
      "Finished 444200\n",
      "Finished 449000\n",
      "Finished 449100\n",
      "Finished 449200\n",
      "Finished 456000\n",
      "Finished 456100\n",
      "Finished 456110\n",
      "Finished 457000\n",
      "Finished 457100\n",
      "Finished 457200\n",
      "Finished 458000\n",
      "Finished 458100\n",
      "Finished 458200\n",
      "Finished 458300\n",
      "Finished 459000\n",
      "Finished 459110\n",
      "Finished 459200\n",
      "Finished 459300\n",
      "Finished 4590A1\n",
      "Finished 459900\n",
      "Finished 48-490\n",
      "Finished 481000\n",
      "Finished 481100\n",
      "Finished 481200\n",
      "Finished 482000\n",
      "Finished 483000\n",
      "Finished 483100\n",
      "Finished 483200\n",
      "Finished 484000\n",
      "Finished 485000\n",
      "Finished 485100\n",
      "Finished 485200\n",
      "Finished 485300\n",
      "Finished 485400\n",
      "Finished 485500\n",
      "Finished 485900\n",
      "Finished 486000\n",
      "Finished 486100\n",
      "Finished 486200\n",
      "Finished 486900\n",
      "Finished 487-80\n",
      "Finished 487000\n",
      "Finished 487100\n",
      "Finished 487200\n",
      "Finished 487900\n",
      "Finished 488000\n",
      "Finished 488100\n",
      "Finished 488200\n",
      "Finished 488300\n",
      "Finished 488400\n",
      "Finished 488500\n",
      "Finished 488900\n",
      "Finished 492000\n",
      "Finished 492100\n",
      "Finished 492200\n",
      "Finished 493000\n",
      "Finished 510000\n",
      "Finished 512000\n",
      "Finished 512100\n",
      "Finished 512130\n",
      "Finished 512200\n",
      "Finished 513000\n",
      "Finished 513110\n",
      "Finished 513200\n",
      "Finished 516000\n",
      "Finished 516110\n",
      "Finished 516120\n",
      "Finished 516210\n",
      "Finished 517000\n",
      "Finished 518000\n",
      "Finished 519000\n",
      "Finished 520000\n",
      "Finished 521-20\n",
      "Finished 521000\n",
      "Finished 522000\n",
      "Finished 522200\n",
      "Finished 522290\n",
      "Finished 5220A1\n",
      "Finished 524000\n",
      "Finished 524100\n",
      "Finished 524114\n",
      "Finished 524120\n",
      "Finished 524200\n",
      "Finished 524210\n",
      "Finished 524290\n",
      "Finished 523,50\n",
      "Finished 523000\n",
      "Finished 525000\n",
      "Finished 525100\n",
      "Finished 525900\n",
      "Finished 530000\n",
      "Finished 531000\n",
      "Finished 532000\n",
      "Finished 532100\n",
      "Finished 5320A1\n",
      "Finished 533000\n",
      "Finished 540000\n",
      "Finished 541000\n",
      "Finished 541100\n",
      "Finished 541200\n",
      "Finished 541300\n",
      "Finished 541330\n",
      "Finished 541380\n",
      "Finished 541400\n",
      "Finished 541500\n",
      "Finished 541600\n",
      "Finished 541700\n",
      "Finished 541710\n",
      "Finished 541720\n",
      "Finished 541800\n",
      "Finished 541900\n",
      "Finished 541920\n",
      "Finished 541940\n",
      "Finished 550000\n",
      "Finished 551000\n",
      "Finished 560000\n",
      "Finished 561000\n",
      "Finished 561100\n",
      "Finished 561200\n",
      "Finished 561300\n",
      "Finished 561320\n",
      "Finished 561400\n",
      "Finished 561500\n",
      "Finished 561600\n",
      "Finished 561610\n",
      "Finished 561620\n",
      "Finished 561700\n",
      "Finished 561710\n",
      "Finished 561730\n",
      "Finished 561900\n",
      "Finished 562000\n",
      "Finished 562100\n",
      "Finished 562200\n",
      "Finished 562900\n",
      "Finished 610000\n",
      "Finished 611000\n",
      "Finished 611100\n",
      "Finished 611105\n",
      "Finished 611102\n",
      "Finished 611103\n",
      "Finished 6112-3\n",
      "Finished 611200\n",
      "Finished 611205\n",
      "Finished 611202\n",
      "Finished 611203\n",
      "Finished 611300\n",
      "Finished 611305\n",
      "Finished 611302\n",
      "Finished 611303\n",
      "Finished 6114-7\n",
      "Finished 611400\n",
      "Finished 611405\n",
      "Finished 611402\n",
      "Finished 611403\n",
      "Finished 611500\n",
      "Finished 611505\n",
      "Finished 611502\n",
      "Finished 611503\n",
      "Finished 611600\n",
      "Finished 611605\n",
      "No line items found.\n",
      "Finished 611603\n",
      "Finished 611700\n",
      "Finished 611705\n",
      "Finished 611703\n",
      "Finished 620000\n",
      "Finished 621000\n",
      "Finished 621100\n",
      "Finished 621200\n",
      "Finished 621300\n",
      "Finished 621310\n",
      "Finished 621320\n",
      "Finished 621330\n",
      "Finished 621340\n",
      "Finished 621390\n",
      "Finished 621400\n",
      "Finished 621420\n",
      "Finished 621500\n",
      "Finished 621600\n",
      "Finished 621900\n",
      "Finished 621910\n",
      "Finished 621990\n",
      "Finished 622000\n",
      "Finished 622100\n",
      "Finished 622105\n",
      "Finished 622102\n",
      "Finished 622103\n",
      "Finished 622200\n",
      "Finished 622205\n",
      "Finished 622202\n",
      "Finished 622203\n",
      "Finished 622300\n",
      "Finished 622305\n",
      "Finished 622302\n",
      "Finished 622303\n",
      "Finished 623000\n",
      "Finished 623100\n",
      "Finished 623200\n",
      "Finished 623210\n",
      "Finished 623220\n",
      "Finished 623300\n",
      "Finished 623900\n",
      "Finished 624000\n",
      "Finished 624100\n",
      "Finished 624120\n",
      "Finished 6242-3\n",
      "Finished 624200\n",
      "Finished 624300\n",
      "Finished 624400\n",
      "Finished 710000\n",
      "Finished 711000\n",
      "Finished 711100\n",
      "Finished 711110\n",
      "Finished 711200\n",
      "Finished 7113-4\n",
      "Finished 711300\n",
      "Finished 711400\n",
      "Finished 711500\n",
      "Finished 712000\n",
      "Finished 713000\n",
      "Finished 713100\n",
      "Finished 713200\n",
      "Finished 713900\n",
      "Finished 713940\n",
      "Finished 720000\n",
      "Finished 721000\n",
      "Finished 721100\n",
      "Finished 721120\n",
      "Finished 721200\n",
      "Finished 721300\n",
      "Finished 722000\n",
      "Finished 722300\n",
      "Finished 722400\n",
      "Finished 722500\n",
      "Finished 722511\n",
      "Finished 810000\n",
      "Finished 811000\n",
      "Finished 811100\n",
      "Finished 811110\n",
      "Finished 811120\n",
      "Finished 811190\n",
      "Finished 811200\n",
      "Finished 811300\n",
      "Finished 811400\n",
      "Finished 812000\n",
      "Finished 812100\n",
      "Finished 812200\n",
      "Finished 812300\n",
      "Finished 812900\n",
      "Finished 813000\n",
      "Finished 8132-3\n",
      "Finished 813200\n",
      "Finished 813300\n",
      "Finished 8134-9\n",
      "Finished 813400\n",
      "Finished 813900\n",
      "Finished 813930\n",
      "Finished 814000\n",
      "Finished 900000\n",
      "Finished 910000\n",
      "Finished 491000\n",
      "Finished 999100\n",
      "Finished 999200\n",
      "Finished 999300\n"
     ]
    }
   ],
   "source": [
    "# Update the summaries for the \"All industries\" rows\n",
    "def calculate_summary_scores_for_all_industries():\n",
    "    industry_codes_sql = \"\"\"\n",
    "SELECT\n",
    "    id,\n",
    "    industry_code\n",
    "FROM\n",
    "    bls_matrix\n",
    "WHERE\n",
    "    occupation_type = 'Summary' AND\n",
    "    occupation_code = '00-0000' AND\n",
    "    alpha IS NULL\n",
    "\"\"\"\n",
    "    for row in tqdm(c.execute(industry_codes_sql).fetchall()):\n",
    "        id, industry_code = row\n",
    "\n",
    "        query_sql = \"\"\"\n",
    "SELECT\n",
    "    id,\n",
    "    employment_2022,\n",
    "    alpha,\n",
    "    beta,\n",
    "    zeta\n",
    "FROM\n",
    "    bls_matrix\n",
    "WHERE\n",
    "    industry_code = :industry_code AND\n",
    "    occupation_type = 'Line item'\n",
    "\"\"\"\n",
    "        line_items = c.execute(query_sql, {\"industry_code\": industry_code}).fetchall()\n",
    "        if len(line_items) == 0:\n",
    "            print(f\"No line items found.\")\n",
    "            continue\n",
    "\n",
    "        weighted_alpha, weighted_beta, weighted_zeta = sumprod(line_items)\n",
    "\n",
    "        # update the row with the weighted average\n",
    "        update_single_row(id, weighted_alpha, weighted_beta, weighted_zeta)\n",
    "        print(f\"Finished {industry_code}\")\n",
    "    conn.commit()\n",
    "\n",
    "calculate_summary_scores_for_all_industries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gptsaregpts-bRn197-3-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
